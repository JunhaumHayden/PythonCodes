{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyMXnjQVNjaMipB0qKngZLrs"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Sobre o notebook\n",
    "\n",
    "Esse notebook contém diversos desafios envolvendo os aprendizados de cada aula. É um notebook construído com o enunciado de cada desafio e com espaço para construir e executar suas soluções. Se for necessário adicionar mais células de código para solucionar o desafio, fique à vontade para acrescentar."
   ],
   "metadata": {
    "id": "_kwAaQ36gLQ1"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Aula 1"
   ],
   "metadata": {
    "id": "fbQaJ7XHqd2p"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Desafio 1\n",
    "\n",
    "Faça a leitura da base de dados de diabetes e realize a divisão dos dados em variáveis explicativas e variável alvo (x e y)."
   ],
   "metadata": {
    "id": "XXpTDkQmqgGT"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "o-clr688LDl2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Desafio 2\n",
    "\n",
    "Realize a divisão dos dados entre treino e teste."
   ],
   "metadata": {
    "id": "dn6U1p70qw7p"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "AKqvmM8QXkHW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Desafio 3\n",
    "\n",
    "Crie 2 modelos utilizando os algoritmos [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) e [RandomForestClassifer](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) e avalie a acurácia de treino e teste, escolhendo valores para o parâmetro `max_depth` para os modelos não se especializarem demais no padrão dos dados de treino."
   ],
   "metadata": {
    "id": "IcmuQBIyxHc8"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "YPeQmyV1YhwA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Desafio 4\n",
    "\n",
    "Construa uma matriz de confusão para cada um dos modelos para avaliar o desempenho das previsões."
   ],
   "metadata": {
    "id": "luUySRh5xNL1"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "_sufI0QkZKvu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Aula 2"
   ],
   "metadata": {
    "id": "dQtdWeLPZ2qI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Desafio 1\n",
    "\n",
    "Extraia as métricas acurácia, recall, precisão e F1-Score dos modelos de classificação gerados no desafio da aula 1."
   ],
   "metadata": {
    "id": "j3gbWXPaZ6b_"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "b-TqlLAeaKNH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Desafio 2\n",
    "\n",
    "Obtenha a curva ROC e a métrica AUC dos modelos de classificação gerados no desafio da aula 1, comparando as curvas no mesmo gráfico.\n",
    "\n",
    "*Como uma dica, vasculhe a documentação do `Scikit-learn` a partir deste [link](https://scikit-learn.org/stable/auto_examples/release_highlights/plot_release_highlights_0_22_0.html#new-plotting-api) e verifique uma forma de apresentar os resultados das curvas no mesmo gráfico usando o matplotlib*"
   ],
   "metadata": {
    "id": "Iy6nX8iQZ_JJ"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "CBfg1CYkdUFr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Desafio 3\n",
    "\n",
    "Obtenha a curva precisão x recall e a métrica AP dos modelos de classificação gerados no desafio da aula 1, comparando as curvas no mesmo gráfico.\n",
    "\n",
    "*Como uma dica, vasculhe a documentação do `Scikit-learn` a partir deste [link](https://scikit-learn.org/stable/auto_examples/release_highlights/plot_release_highlights_0_22_0.html#new-plotting-api) e verifique uma forma de apresentar os resultados das curvas no mesmo gráfico usando o matplotlib*"
   ],
   "metadata": {
    "id": "MtAISYmrZ_VR"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "n5UUgmk4af0I"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Desafio 4\n",
    "\n",
    "Gere os relatórios de métricas dos modelos de classificação gerados no desafio da aula 1."
   ],
   "metadata": {
    "id": "QC-mYuowZ_YO"
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1 - Para extrair as métricas de um modelo, vamos primeiro importar as funções que calculam automaticamente:\n",
    "\n",
    "    accuracy_score\n",
    "    recall_score\n",
    "    precision_score\n",
    "    f1_score"
   ]
  },
  {
   "cell_type": "code",
   "source": "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
   "metadata": {
    "id": "AZIfQPpJZ3rG",
    "ExecuteTime": {
     "end_time": "2025-08-06T15:01:02.614369Z",
     "start_time": "2025-08-06T15:01:02.261544Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Agora vamos calcular cada uma das métricas para os dois modelos, utilizando os dados reais e valores previstos:\n",
    "previsao_arvore = arvore.predict(x_val)\n",
    "\n",
    "print(f'Acurácia (Decision Tree): {accuracy_score(y_val, previsao_arvore)}')\n",
    "print(f'Recall (Decision Tree): {recall_score(y_val, previsao_arvore)}')\n",
    "print(f'Precisão (Decision Tree): {precision_score(y_val, previsao_arvore)}')\n",
    "print(f'F1_Score (Decision Tree): {f1_score(y_val, previsao_arvore)}')\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "previsao_rf = random_forest.predict(x_val)\n",
    "\n",
    "print(f'Acurácia (Random Forest): {accuracy_score(y_val, previsao_rf)}')\n",
    "print(f'Recall (Random Forest): {recall_score(y_val, previsao_rf)}')\n",
    "print(f'Precisão (Random Forest): {precision_score(y_val, previsao_rf)}')\n",
    "print(f'F1_Score (Random Forest): {f1_score(y_val, previsao_rf)}')\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2 - Para obter o gráfico da curva ROC e a métrica AUC, vamos primeiro importar as funções para gerar o gráfico e calcular a métrica:"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "from sklearn.metrics import RocCurveDisplay, roc_auc_score\n"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Para apresentar os resultados da curva ROC no mesmo gráfico, podemos armazenar o gráfico em uma variável e utilizar o parâmetro ax para utilizar o gráfico já existente como base:\n",
    "curva_roc = RocCurveDisplay.from_predictions(y_val, previsao_arvore, name = 'Decision Tree')\n",
    "curva_roc = RocCurveDisplay.from_predictions(y_val, previsao_rf, name = 'Random Forest', ax = curva_roc.ax_)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 3 - Para obter o gráfico da curva precisão x recall e a métrica AP, vamos primeiro importar as funções para gerar o gráfico e calcular a métrica:\n",
    "\n",
    "from sklearn.metrics import PrecisionRecallDisplay, average_precision_score\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Para apresentar os resultados da curva precisão x recall no mesmo gráfico, podemos armazenar o gráfico em uma variável e utilizar o parâmetro ax para utilizar o gráfico já existente como base:\n",
    "\n",
    "curva_precision_recall = PrecisionRecallDisplay.from_predictions(y_val, previsao_arvore, name = 'Decision Tree')\n",
    "curva_precision_recall = PrecisionRecallDisplay.from_predictions(y_val, previsao_rf, name = 'Random Forest', ax = curva_precision_recall.ax_)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Agora basta usar o método average_precision_score para calcular o AP dos dois modelos:\n",
    "\n",
    "print(f'AP (Decision Tree): {average_precision_score(y_val, previsao_arvore)}')\n",
    "print(f'AP (Random Forest): {average_precision_score(y_val, previsao_rf)}')\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 4 - Para gerar o relatório de métricas, primeiro precisamos importar a função classification_report:\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# A partir daí, podemos gerar os relatórios para cada um dos modelos, utilizando os valores reais e previstos:\n",
    "print('Decision Tree')\n",
    "print(classification_report(y_val, previsao_arvore))\n",
    "print('Random Forest')\n",
    "print(classification_report(y_val, previsao_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Aula 3\n",
    "- dados de pacientes a serem diagnosticados com diabetes ou não."
   ],
   "metadata": {
    "id": "1uD6CKpmk-ud"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Desafio 1\n",
    "\n",
    "- Crie uma função para calcular o intervalo de confiança dos resultados de uma validação cruzada com 2 desvios padrão. A função precisa ter um parâmetro para receber uma lista com os desempenhos da validação cruzada e outro para apresentar o nome do modelo utilizado na validação cruzada.\n",
    "\n",
    "- No processo de validação cruzada, são gerados diferentes modelos para cada divisão realizada nos dados e consequentemente diferentes valores de métricas de avaliação. Para encontrar um resultado médio das métricas, pode ser construído um intervalo de confiança a partir da média e desvio padrão das métricas. Crie uma função para calcular o intervalo de confiança dos resultados de uma validação cruzada com 2 desvios padrão. A função precisa de 2 parâmetros: um para receber uma lista com os resultados das métricas da validação cruzada e outro para receber o nome do algoritmo. Para gerar o intervalo de confiança, extraia a média dos resultados da lista e o desvio padrão. O intervalo de confiança deve ser apresentado em um print com o valor mínimo sendo a média subtraída de 2 desvios padrão e o valor máximo sendo a média somada de 2 desvios padrão. Exemplo de retorno da função:\n",
    "\n",
    "> Intervalo de confiança (\"nome do modelo\"): [\"valor mínimo do intervalo\", \"valor máximo do intervalo\"]\n",
    "\n",
    "#### Para calcular o intervalo de confiança dos resultados da validação cruzada:\n",
    " Precisamos da lista de resultados e também do nome do modelo para apresentar na função print. Vamos criar uma função chamada intervalo_conf que recebe dois parâmetros: resultados e nome_modelo.\n",
    "\n",
    "A partir dos resultados, podemos extrair a média e desvio padrão e gerar o intervalo de confiança que está a uma distância de dois desvios padrão abaixo e acima dessa média:"
   ],
   "metadata": {
    "id": "_ksJQ1Ca9Alx"
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def intervalo_conf(resultados, nome_modelo):\n",
    "    media = resultados.mean()\n",
    "    desvio_padrao = resultados.std()\n",
    "    print(f'Intervalo de confiança ({nome_modelo}): [{media - 2*desvio_padrao}, {min(media + 2*desvio_padrao, 1)}]')\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Bg7Uh6QyTyB5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Desafio 2\n",
    "\n",
    "Avalie o desempenho dos modelos com um intervalo de confiança utilizando a validação cruzada com o método [`KFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html), usando 10 partes e embaralhando os dados antes da separação. Use o método [`cross_val_score`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) que não retorna o tempo de execução, apenas as métricas.\n",
    "\n",
    "- KFold é a estratégia mais simples de validação cruzada, que permite a divisão aleatória dos dados em k partes, sendo utilizada uma parte para validação e o restante para treinamento do modelo. O processo de criação de modelos é feito novamente até que todas as partes sejam utilizadas como validação. Sabendo disso, avalie o desempenho dos modelos com um intervalo de confiança utilizando a validação cruzada com o método KFold, usando 10 partes, com uso do parâmetro n_splits e embaralhando os dados antes da separação com o parâmetro shuffle. Use o método cross_val_score que não retorna o tempo de execução, apenas as métricas."
   ],
   "metadata": {
    "id": "aA2RAJvGlCM1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 2 - O primeiro passo a se fazer é importar a função cross_val_score e o método KFold:\n",
    "from sklearn.model_selection import cross_val_score, KFold\n"
   ],
   "metadata": {
    "id": "QeAunVFjnSOi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Feito isso, vamos inicializar os modelos e utilizar o KFold com o n_splits=10 para gerar uma divisão de 10 partes. Além disso, vamos utilizar o parâmetro shuffle=True para embaralhar os dados antes de realizar a separação.\n",
    "\n",
    "Posteriormente, vamos usar o método cross_val_score para realizar o procedimento de validação cruzada com os dois modelos e gerar o intervalo de confiança a partir dos resultados:"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "arvore = DecisionTreeClassifier(max_depth = 3)\n",
    "random_forest = RandomForestClassifier(max_depth = 2)\n",
    "\n",
    "kf = KFold(n_splits = 10, shuffle = True, random_state = 5)\n",
    "\n",
    "resultado_arvore = cross_val_score(arvore, x, y, cv = kf)\n",
    "resultado_rf = cross_val_score(random_forest, x, y, cv = kf)\n",
    "\n",
    "intervalo_conf(resultado_arvore, 'Decision Tree')\n",
    "intervalo_conf(resultado_rf, 'Random Forest')\n"
   ]
  },
  {
   "metadata": {
    "id": "FXHAOmL4lFBp"
   },
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Desafio 3\n",
    "\n",
    "- Avalie o desempenho dos modelos com um intervalo de confiança utilizando a validação cruzada (`cross_val_score`) com o método [`StratifiedKFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold), usando 10 partes e embaralhando os dados antes da separação e avaliando a métrica F1-Score.\n",
    "\n",
    "- No processo de divisão de dados com o KFold aleatório, pode ser que a proporção de cada categoria da variável alvo não seja mantida em cada uma das partes dos dados. Para manter essa proporção em cada uma das partes, podemos utilizar o KFold estratificado, deixando o processo de validação de dados bem mais consistente. Avalie o desempenho dos modelos com um intervalo de confiança utilizando a validação cruzada (cross_val_score) com o método StratifiedKFold, com uso do parâmetro n_splits e embaralhando os dados antes da separação com o parâmetro shuffle e avaliando a métrica F1-Score usando o parâmetro scoring."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 3 - O primeiro passo a se fazer é importar a função cross_val_score e o método StratifiedKFold:\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "O passo segue de forma bem parecida com o desafio anterior, se diferenciando na escolha do método de validação que será estratificado, com o método StratifiedKFold. Além disso, a métrica de avaliação precisa ser alterada para o f1, a partir do parâmetro scoring da função cross_val_score:"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "arvore = DecisionTreeClassifier(max_depth = 3)\n",
    "random_forest = RandomForestClassifier(max_depth = 2)\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 5)\n",
    "\n",
    "resultado_arvore = cross_val_score(arvore, x, y, cv = skf, scoring = 'f1')\n",
    "resultado_rf = cross_val_score(random_forest, x, y, cv = skf, scoring =  'f1')\n",
    "\n",
    "intervalo_conf(resultado_arvore, 'Decision Tree')\n",
    "intervalo_conf(resultado_rf, 'Random Forest')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Desafio 4\n",
    "\n",
    "- Avalie o desempenho dos modelos utilizando a validação cruzada (`cross_val_score`) com o método [`LeaveOneOut`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html).\n",
    "\n",
    "- O método LeaveOneOut vai gerar um modelo para cada uma das linhas da base de dados, portanto a lista de resultados terá taxa de acerto apenas de 0 ou 1 para cada modelo. Dessa forma, extraia apenas a média do resultado, sem utilizar o intervalo de confiança.\n",
    "\n",
    "- Em conjuntos de dados com poucos registros (poucas linhas), as estratégias de separação dos dados para validação podem fazer com que reste pouca informação nos dados de treinamento, fazendo com que o modelo não compreenda bem o padrão dos dados. O LeaveOneOut é uma estratégia para contornar esse problema, utilizando apenas um registro como dado de validação. Avalie o desempenho dos modelos utilizando a validação cruzada (cross_val_score) com o método LeaveOneOut.\n",
    "\n",
    "> O método LeaveOneOut vai gerar um modelo para cada uma das linhas da base de dados, portanto a lista de resultados terá taxa de acerto apenas de 0 ou 1 para cada modelo. Dessa forma, extraia apenas a média do resultado com o método mean(), sem utilizar o intervalo de confiança.\n"
   ],
   "metadata": {
    "id": "PffR585slFHS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 4 - O primeiro passo a se fazer é importar a função cross_val_score e o método LeaveOneOut:\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n"
   ],
   "metadata": {
    "id": "2Fu1i0l9T2F5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "A construção do código se dá de forma bem parecida com os desafios anteriores. Primeiro os modelos são inicializados e depois o método LeaveOneOut é inicializado, sem a necessidade de definir parâmetros, pois ele percorre toda a base de dados até que todos os valores tenham sido escolhidos como dados de validação e todo o restante como dados de treinamento.\n",
    "\n",
    "Aqui vamos calcular apenas a média dos resultados, portanto vamos utilizar o método mean() em cada uma das listas de resultados para obter a acurácia média.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "arvore = DecisionTreeClassifier(max_depth = 3)\n",
    "random_forest = RandomForestClassifier(max_depth = 2)\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "resultado_arvore = cross_val_score(arvore, x, y, cv = loo)\n",
    "resultado_rf = cross_val_score(random_forest, x, y, cv = loo)\n",
    "\n",
    "print(f'Acurácia média (Decision Tree): {resultado_arvore.mean()}')\n",
    "print(f'Acurácia média (Random Forest):{resultado_rf.mean()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Aula 4"
   ],
   "metadata": {
    "id": "LkuY1LZDJnnE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Desafio 1\n",
    "\n",
    "- Verifique a proporção de dados da variável alvo do conjunto de dados de diabetes. Essa análise pode ser feita a partir da porcentagem de dados ou com a utilização de um gráfico de contagem para entender se há um desbalanceamento de dados.\n",
    "- O desbalanceamento dos dados da variável alvo pode fazer com que o modelo fique tendencioso a acertar os padrões de apenas da categoria que tem maior quantidade, tornando necessário em alguns casos um tratamento específico de balanceamento de dados. A etapa inicial é identificar se existe ou não o desbalanceamento de dados na variável alvo. Por conta disso, verifique a proporção de dados da variável alvo do conjunto de dados de diabetes. Essa análise pode ser feita a partir da porcentagem de dados, usando o método value_counts(normalize=True) ou com a utilização de um gráfico de contagem, usando o gráfico countplot da biblioteca seaborn para entender se há um desbalanceamento de dados."
   ],
   "metadata": {
    "id": "8H-XGS58Jo97"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 1 - Para checar a proporção dos dados na variável alvo, podemos usar o método value_counts que realiza a contagem dos dados de cada categoria da coluna. Podemos ainda usar o parâmetro normalize = True para retornar o resultado em porcentagem:\n",
    "dados['diabetes'].value_counts(normalize = True)\n"
   ],
   "metadata": {
    "id": "ymR1fC95T2l5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Outra forma de analisar é por meio de um gráfico. Podemos usar o countplot() da biblioteca seaborn:\n",
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(dados, x = 'diabetes');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Desafio 2\n",
    "\n",
    "- Utilize um [`pipeline`](https://imbalanced-learn.org/stable/references/generated/imblearn.pipeline.Pipeline.html) contendo ajuste do modelo e o balanceamento dos dados usando o oversampling com [`SMOTE`](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html), obtendo a média do F1-Score de uma validação cruzada com `StratifiedKFold`.\n",
    "- Ao realizar o balanceamento de dados em uma validação cruzada, é necessário utilizar um pipeline, para que os dados de validação não sejam balanceados, se mantendo no padrão dos dados do mundo real. Utilize um pipeline contendo ajuste do modelo e o balanceamento dos dados usando o oversampling com SMOTE, obtendo a média do F1-Score de uma validação cruzada com StratifiedKFold."
   ],
   "metadata": {
    "id": "OMJ-IW4NJr4M"
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 2 - O primeiro passo é importar o método Pipeline e o SMOTE para balancear os dados:\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Feito isso, podemos inicializar o modelo, criar o pipeline com as tarefas de oversampling e do modelo, e realizar a validação cruzada com o StratifiedKfold, obtendo a média da métrica F1-Score:\n",
    "arvore = DecisionTreeClassifier(max_depth = 3)\n",
    "pipeline = imbpipeline([('oversample', SMOTE()), ('arvore', arvore)])\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 5)\n",
    "resultado_arvore = cross_val_score(pipeline, x, y, cv = skf, scoring = 'f1')\n",
    "print(f'F1 (Decision Tree):{resultado_arvore.mean()}')\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "random_forest = RandomForestClassifier(max_depth = 2)\n",
    "pipeline = imbpipeline([('oversample', SMOTE()), ('random_forest', random_forest)])\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 5)\n",
    "resultado_rf = cross_val_score(pipeline, x, y, cv = skf, scoring = 'f1')\n",
    "print(f'F1 (Random Forest):{resultado_rf.mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "MXJSDAQUT3up"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Desafio 3\n",
    "\n",
    "- Utilize um [`pipeline`](https://imbalanced-learn.org/stable/references/generated/imblearn.pipeline.Pipeline.html) contendo ajuste do modelo e o balanceamento dos dados usando o undersampling com [`Nearmiss`](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html) na sua versão 3, obtendo a média do F1-Score de uma validação cruzada com `StratifiedKFold`.\n",
    "- Além do oversampling, é possível utilizar a estratégia de undersampling para fazer o balanceamento dos dados. Apesar de serem estratégias distintas, ambas necessitam de um pipeline por se tratar de balanceamento de dados em uma validação cruzada. Utilize um pipeline contendo ajuste do modelo e o balanceamento dos dados usando o undersampling com NearMiss na sua versão 3, obtendo a média do F1-Score de uma validação cruzada com StratifiedKFold.\n"
   ],
   "metadata": {
    "id": "rSKJ6r9gJuq0"
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 3 - O primeiro passo é importar o método Pipeline e o NearMiss para balancear os dados:\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from imblearn.under_sampling import NearMiss\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Feito isso, podemos inicializar o modelo, criar o pipeline com as tarefas de undersampling e do modelo, e realizar a validação cruzada com o StratifiedKfold, obtendo a média da métrica F1-Score:\n",
    "arvore = DecisionTreeClassifier(max_depth = 3)\n",
    "pipeline = imbpipeline([('undersample', NearMiss(version = 3)), ('arvore', arvore)])\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 5)\n",
    "resultado_arvore = cross_val_score(pipeline, x, y, cv = skf, scoring = 'f1')\n",
    "print(f'F1 (Decision Tree):{resultado_arvore.mean()}')\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "random_forest = RandomForestClassifier(max_depth = 2)\n",
    "pipeline = imbpipeline([('undersample', NearMiss(version = 3)), ('random_forest', random_forest)])\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 5)\n",
    "resultado_rf = cross_val_score(pipeline, x, y, cv = skf, scoring = 'f1')\n",
    "print(f'F1 (Random Forest):{resultado_rf.mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "FA2DCsQbT5Go"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Desafio 4\n",
    "\n",
    "- Escolha o modelo que obteve o melhor desempenho ao comparar as estratégias de oversampling e undersampling e realize o teste do modelo nos dados de teste que foram separados no início dos desafios.\n",
    "- Após realizar diversas análises e aprimorar o desempenho dos modelos, chega a etapa final, que consiste em selecionar o modelo com melhor desempenho e fazer a avaliação final em um conjunto de dados de teste, que não foi visto durante o processo de treinamento e validação. Escolha o modelo que obteve o melhor desempenho ao comparar as estratégias de oversampling e undersampling e treine um modelo usando todos os dados com a melhor estratégia. Realize a avaliação do modelo usando os dados de teste que foram separados no início dos desafios, obtendo o relatório de métricas e matriz de confusão."
   ],
   "metadata": {
    "id": "6ZpXGQyPJwNl"
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 4 - O modelo que obteve maior desempenho nos testes do desafio foi o RandomForest, usando o max_depth = 2 na estratégia de undersampling. Portanto vamos balancear os dados e utilizar esse modelo em todos os dados balanceados. Por fim vamos validar o modelo em dados de teste, não vistos até então:\n",
    "\n",
    "undersample = NearMiss(version = 3)\n",
    "x_balanceado, y_balanceado = undersample.fit_resample(x, y)\n",
    "\n",
    "modelo = RandomForestClassifier(max_depth = 2)\n",
    "modelo.fit(x_balanceado, y_balanceado)\n",
    "y_previsto = modelo.predict(x_teste)\n",
    "\n",
    "print(classification_report(y_teste, y_previsto))\n",
    "ConfusionMatrixDisplay.from_predictions(y_teste, y_previsto);\n"
   ]
  },
  {
   "metadata": {
    "id": "x7N_pyEuT6dh"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
